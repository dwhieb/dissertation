\chapter{Conclusion}
\label{ch:conclusion}

\blockquote{This chapter summarizes the methods and main findings of this study, and considers the implications of those results for theories of lexical categories. I argue that the data provide compelling evidence in favor of functional approaches to lexical categorization, most especially cognitive prototype theory and Croft's theory of lexical categories as typological markedness patterns. I also argue for a reversal of the canonical position on parts of speech: instead of working from the default assumption that all languages have clearly-defined or even loosely-defined parts of speech, we should begin from the understanding that dedicated referring, predicating, or modifying constructions develop diachronically, and that even when they do, they do not do so for the entire lexicon, or in all areas of the grammar equally. Even languages like \idx{English}, whose lexemes pattern strongly with the standard prototypes of noun, verb, and adjectives, nonetheless exhibit varying degrees of flexibility for different lexemes. Lexical categories are not a given in grammar. I conclude by discussing some limitations of the present study and avenues for future research, followed by closing remarks.}

\section{Introduction}
\label{sec:5.1}

This chapter presents a summary of the study and its major findings (\secref*{sec:5.2}). It provides a discussion of the theoretical implications of those findings (\secref*{sec:5.3}) and directions for future research (\secref*{sec:5.4}). I conclude that researchers should shift from treating lexical flexibility as an exotic analytical problem to a foundational feature of language (\secref*{sec:5.5}).

Lexical flexibility—the use of a lexical item in more than one discourse function (reference, predication, or modification) with zero coding for that function—has historically been an intractable problem for theories of parts of speech. The Classical tradition inherited from Ancient Greek and Latin requires that each lexeme be sorted into mutually exclusive lexical categories defined by a clear set of necessary and sufficient conditions. Forms that seem to cross-cut these categorial boundaries thus present a theoretical quandry.

One common solution to this problem is to analyze any form used for more than one discourse function as a case of heterosemy—a special case of homonymy in which two lexemes share the same form but belong to distinct word classes \parencite{Lichtenberk1991}. A second common solution is to adjust the features that define the relevant word classes so as to preserve the traditional classification scheme. This always involves privileging certain kinds of evidence for lexical categories over others, or excluding certain morphosyntactic evidence entirely. However, both of these responses shift the focus away from the interesting ways in which categories differ across languages. Even when subtle evidence for categorical distinctions in flexible languages is found, there remain drastic and qualitative differences in the way that those categorise are realized as compared to other languages with more clearly demarcated categories. Typologists should not be satisfied to gloss over these differences. Instead, differences in the strength of expression of lexical categories in a language should be taken as a dimension of variation to mapped out and explored in a robust empirical way, as has been attempted here.

A final answer to the existence of lexical flexibility is to define new kinds of lexical categories such as \enquote{contentives}, \enquote{flexibles}, or \enquote{non-verbs} \parencites{HengeveldRijkhoff2005}{Luuk2010} for the purpose of accommodating the flexible forms. What all the above approaches have in common is their commitment to a small set of well-defined word classes. They also generally agree on the empirical facts of the matter. Disagreements over the analysis of flexible forms arise primarily from disagreements over the relative importance of different pieces of evidence rather than the accuracy of the evidence itself \parencites[235]{Wetzer1992}[32]{Stassen1997}[58]{CroftLier2012}. Yet, though researchers have debated the definitional criteria for lexical categories for as long as modern linguistics has existed, there is still no consensus. Analyses of lexical flexibility depend primarily on the theoretical commitments of the researcher rather than any crucial pieces of evidence. Methodological opportunism, in which researchers select the definitional criteria for lexical categories that best support their theoretical commitments while dismissing or deemphasizing contradictory criteria \parencite[30]{Croft2001b}, is a rampant problem in research on word classes.

A consequence of this methodological opportunism is that until recently lexical flexibility was not appreciated as the interesting phenomenon it is. Flexible forms were placed into one lexical category or another and the problem was considered solved. But to lump flexible forms in with overtly derived forms ignores the fact that there is something unique about them—namely that they can appear in different discourse functions with no overt morphological indicator of their discourse function. Just how prevalent is this phenomenon? Why do these words in particular behave this way while others do not? How productive is it? Are the meaning shifts that occur in functional shift different from or the same as the meaning shifts that occur in cases of overt derivation? An attitude that treats flexible forms as a problem to be solved preempts these kinds of questions—or at least shifts focus away from them. Regardless of one's theoretical analysis of flexible forms, their behavior is substantively different from non-flexible ones, and this fact merits investigation.

In the past three decades, however, more and more researchers have come to treat lexical flexibility as an object of study in its own right and attempted to answer questions like the ones above. The theoretical perspectives on lexical flexibility remain every bit as varied as before, with some researchers fitting flexible forms into the Classical categories \parencites{Baker2003}{Dixon2004}{Floyd2011}{Chung2012}{Palmer2017}, other researchers proposing new ones \parencites{HengeveldRijkhoff2005}{Luuk2010}, and still other researchers abandoning the commitment to lexical categories entirely \parencites{Gil1994}{Broschart1997}{Gil2005}. Nonetheless, more and more scholars are interested in how lexical flexibility operates within and across languages, as evidenced by the growing number of edited volumes on the topic \parencites{VogelComrie2000}{LoisVapnarsky2003}{EvansOsada2005}{AnsaldoDonPfau2010}{RijkhoffLier2013}{SimoneMasini2014}{BlaszczakKlimekJankowskaMigdalski2015}{Lier2017}{VapnarskyVeneziano2017a}{VapnarskyVeneziano2017b}{CuyckensHeyvaertHartmann2019}.

Our understanding of lexical flexibility has, however, still been quite limited. In particular, we knew little about the extent of lexical flexibility within and across languages. This dissertation makes a first contribution to addressing this question, as described in the following section.

\section{Summary of the study}
\label{sec:5.2}

This dissertation is a quantitative corpus-based study of lexical flexibility in \idx{English} (Indo-European > Germanic) and \idx{Nuuchahnulth} (Wakashan > Southern Wakashan). It has focused on answering the following four research questions using corpora of naturalistic spoken data from each language:

\begin{enumerate}[
  label      = {\textbf{R\arabic*:}},
  leftmargin = *,
  ref        = {R\arabic*}
]
  \item\label{R1C} How flexible are lexical items in English and Nuuchahnulth?
  \item\label{R2C} Is there a correlation between degree of lexical flexibility and size of the corpus?
  \item\label{R3C} Is there a correlation between degree of lexical flexibility for a lexical item and frequency (or corpus dispersion)?
  \item\label{R4C} How do the semantic properties of lexical items pattern with respect to their flexibility?
\end{enumerate}

Answering \ref{R1C} required establishing a means of measuring the degree of lexical flexibility for individual lexical items in a language. This metric needed to be able to capture the intuition that lexical items which are used equally as frequently for different discourse functions are maximally flexible, while lexical items which are used for only one discourse function are minimally flexible. To do this, I first counted the number of times each stem was used for the discourse functions of reference, predication, and modification in samples of spoken discourse from \idx{English} and \idx{Nuuchahnulth}. I then used a statistical diversity measure \parentext{the Shannon diversity index \parencites{Shannon1948}{Shannon1951}} to calculate how evenly the three discourse functions are distributed across its tokens. This resulted in a flexibility rating for each stem ranging from $0$ (maximally inflexible) to $1$ (maximally flexible). These ratings are provided for each stem in both samples in \appref{app:100-item-samples}.

Determining the flexibility ratings for the lexical items in a corpus allows us for the first time to study the extent of lexical flexibility in a comprehensive and empirically accountable way. It was found for the 100-item \idx{English} sample that most stems exhibit some degree of flexibility. That degree of flexibility is generally small ($\sim0.2$). English stems are usually slightly flexible. They tend to have clear prototypes focused around a single discourse function, but regularly display marginal uses in other discourse functions as well. English shows the greatest degree of flexibility between reference and modification, with many lexical items sitting somewhere on a cline between prototypical referents and prototypical modifiers. These data present a more complicated picture of English than has previously been claimed. It is not wholly accurate to say that English has clear and rigid lexical categories \parencites[710]{Rijkhoff2007}[4, 11, 12]{SchachterShopen2007}[122, 126]{Velupillai2012}, but nor is it accurate to say that English exhibits rampant flexibility between different discourse functions \parencites[47--48]{Crystal1967}{Vonen1994}[75--76]{Croft2000}[69]{Croft2001b}{Farrell2001}{Cannon1985}.

Lexical items in \idx{Nuuchahnulth} differ from \idx{English} both in their average degree of flexibility and the way that flexibility is realized. While most stems in the Nuuchahnulth corpus do not occur frequently enough to get a clear assessment of their flexibility (see \secref*{sec:4.4}), those that do often have a high degree of flexibility ($\sim0.6$). They have a strong tendency to be used for multiple discourse functions, primarily reference and predication. Most Nuuchahnulth stems that exhibit any flexibility sit somewhere on a spectrum between all referential uses and all predicative uses, with a relatively smooth cline of attested cases between. Nuuchahnulth stems are infrequently used for modification. These findings align well with existing claims about the language. Many have analyzed Nuuchahnulth as lacking an adjective class (or as having a subclass of verbs called \enquote{adjectives}) \parencites{Swadesh1939b}{Jacobsen1979}{Nakayama2001}, and the fact that Nuuchahnulth does not show a clean division between predicating stems and referring stems is precisely what has garnered the language (and other, similar languages of the Pacific Northwest) so much attention in the literature.

The second question addressed in this dissertation is whether the degree of lexical flexibility for a language or its lexemes correlates with the size of the corpus examined (\ref{R2C}). The motivation for this question stems from the intuition, advanced by some researchers \parencite{MoselHovdhaugen1992}, that all lexical items exhibit flexibility if one examines enough tokens of that lexeme in a corpus. Larger corpora could potentially exhibit more flexibility than smaller corpora. If true, this could mean that the lexical flexibility metric developed in \secref*{sec:3.4.1} needs to be adjusted for corpus size.

To investigate this question, I determined the cumulative flexibility for individual stems in \idx{English} and \idx{Nuuchahnulth} as the number of tokens encountered increased. I also ran this procedure in the aggregate, calculating the cumulative flexibility for the entire language as the size of the corpus used grew. No notable correlations were found in either case. Lexical flexibility ratings for both stems and languages remained flat as the size of the corpus grew. However, this procedure did reveal that it takes a certain minimal number of tokens for one to be certain that they are getting a reliable flexibility rating, and that this minimum varies from word to word. Some stems show notable stochasticity in their flexibility ratings up to $\sim$2,000 tokens, whereas others show a smooth and consistent flexibility rating as early as $\sim$50 tokens. The reason for this variation is not entirely clear, but may be due to the fact that some stems occur in a wider range of syntactic contexts than others, and therefore it takes a larger sample for their average flexibility across these uses to become clear.

In sum, the flexibility of a language or lexeme does not vary as a function of corpus size. Flexibility is synchronically fixed on a per-lexeme basis. This fact is likely a result of the fact that the different discourse contexts in which a lexical item can appear are largely conventionalized. Speakers have item-specific knowledge about which discourse functions a stem can (or cannot) be used in. Some stems have a greater proportion of contexts for one discourse function over others, thus explaining inter-word variation in flexibility ratings.

For \ref{R3C}, I explored the interactions among lexical flexibility, relative frequency (per 1,000 words), and corpus dispersion \parentext{how evenly distributed a lexical item is in the corpus, measured using Deviation of Proportions; \parencite{Gries2008}}. There are multiple ways in which flexibility might be hypothesized to correlate with frequency. First, it might be that a higher degree of flexibility makes stems available to a greater number of discourse contexts, thus leading to increased frequency. Conversely, high frequency words are more cognitively accessible and therefore might make themselves available for more novel uses in different discourse functions. Alternatively, high frequency could also result in a greater degree of entrenchment, such that high frequency words are less flexible than low frequency ones. We have no apriori reason for assuming one of these positions to be true—this is an empirical question requiring an empirical answer.

Corpus frequency itself, however, is perhaps not the best way to capture the idea of how regularly a speaker encounters lexical items. The main reason for this is that tokens of a lexeme may be clustered in just a small number of places in a corpus rather than evenly distributed throughout the corpus. Corpus dispersion—how evenly a word is distributed in a corpus—more closely aligns with our intuitions about what we are attempting to capture when we talk about frequency of exposure. Corpus dispersion has been shown to correlate more closely with various experimental results than does token frequency \parencites{Gries2008}{Gries2010}{Griesfc}. In this study I therefore examined the interactions among all three of flexibility, frequency, and dispersion.

Unfortunately, no conclusions can be drawn regarding the interactions of the three variables on the basis of the available data. Using Generalized Additive Models (GAMs), no significant correlations were found between flexibility, frequency, and corpus dispersion, and the models had very little explanatory value overall.

Finally, \ref{R4C} is a preliminary exploration of the semantics of lexical flexibility. Since the stems in either sample were not annotated in any comprehensive way for semantic class, these results should be taken as preliminary observations in need of further empirical support. With this caveat in mind, human animates were consistently among the low-flexibility items in both languages, undoubtedly a reflection of their highly prototypical status as discourse referents. Prototypical property words, however, showed opposite patterns in the two languages. In \idx{English}, property words having to do with size, age, or physical attributes have consistently low flexibility ratings, yet in \idx{Nuuchahnulth} property words are by far the most flexible items.

An explanation in terms of prototypicality cannot account for this difference. Instead, it seems that the discrepancy has to do with the existence or non-existence of dedicated morphological strategies for modification in each language. While not robustly marked, \idx{English} does have morphological constructions specific to modification (comparatives and superlatives). \idx{Nuuchahnulth}, on the other hand, has no morphology dedicated to modification, just a conventionalized syntactic construction in which the modifier precedes its head. This is the likely impetus behind various researchers analyzing Nuuchahnulth as lacking an Adjective class \parencite[e.g.][]{Nakayama2001}. Since English has dedicated morphological strategies for indicating modification, speakers make use of those constructions for prototypical property words. But since Nuuchahnulth does not have dedicated morphological strategies for modification, speakers avail themselves of other strategies that vary depending on the discourse context. When property words are used to introduce a new referent into the discourse, referring constructions are used (usually with the definite suffix \txn{-ʔi·} in Nuuchahnulth and the definite article in English); when property words are used to attribute a property to an existing referent, predicate constructions are used (often with the durative aspect marker), and the referent serves as the subject of the predicate. This dichotomy nicely parallels the dual discourse function of property words described by \textcite{Thompson1989} for English and Mandarin. Building on the predicate strategy, Nuuchahnulth speakers also have the option of attributing properties to referents via a combination of a root indicating a property and a lexical affix indicating the referent that the property is being attributed to. This strategy is most common when the referent is indefinite or non-identifiable \parencite[144]{Nakayama2001}.

A last observation for \idx{Nuuchahnulth} is that, while object words \emph{may} take aspect markers and action words \emph{may} take the definite suffix \txn{-ʔi·}, these two inflectional markers are almost entirely mutually exclusive, co-occurring on only 17 wordforms out of the 1,935 attested wordforms in the corpus (0.88\%). Despite Nuuchahnulth's extensive flexibility, the language still adheres to the crosslinguistic tendency described by \textcite{HopperThompson1984} for prototypical uses of a lexical item to exhibit inflectional behaviors characteristic of its class. This shows that there are still principled limits on lexical flexibility, even in highly flexible languages like Nuuchahnulth.

\section{Discussion}
\label{sec:5.3}

The primary motivation behind this study was to expand the empirical coverage on lexical flexibility. Much has been written about lexical flexibility in the last three decades especially, but as yet there have been few attempts at comprehensive empirical reporting on the phenomenon \parentext{exceptions being \textcite{Croft1984}, \textcite{Cannon1985}, \textcite{EvansOsada2005}, \textcite{Mithun2017}}. This dissertation is a first quantitative report on lexical flexibility in discourse. What have we learned?

First, it is possible to quantify the degree of lexical flexibility for both languages and individual lexical items in a way that maps to our conception of what lexical flexibility is. By using a diversity index like Shannon's $H$ we can compare flexibility across lexical items and languages in a meaningful way.

Second, we have seen that lexical flexibility is a matter of degree at both the word and language level. The difference between \idx{English} and \idx{Nuuchahnulth} in terms of their flexibility is a matter of degree rather than a difference in kind. Ultimately, both English and Nuuchahnulth display a prominent degree of flexibility—Nuuchahnulth merely displays it to a greater extent than English. The two languages also display that flexibility in different ways. English shows a relatively marginal degree of flexibility for most of its lexemes, whereas Nuuchahnulth shows a relatively high degree of flexibility for most of its lexemes, but primarily between reference and predication, not modification. At a high level, what this also shows is that languages differ in the degree to which individual lexemes are associated with specific, mutually exclusive discourse functions. In a language like English, lexemes tend to be strongly associated with a single discourse function, while less commonly but still frequently allowing for use in other functions. In a language like Nuuchahnulth, lexemes sit anywhere on a continuum of associating more strongly with reference versus predication, but few show a strong degree of association with modification.

The data presented in this dissertation therefore provide strong empirical support of \posscitet[50]{Nakayama2001} claim that lexical categories in \idx{Nuuchahnulth} are best described as statistical tendencies in discourse rather than clearly-defined morphosyntactic classes. Yet this analysis is equally valid for \idx{English} and Nuuchahnulth: English lexemes merely display a stronger statistical tendency towards a single discourse function than do Nuuchahnulth lexemes. In fact, given the fact that mental categorization is prototypal and that morphosyntactic constructions dedicated to specific discourse functions take time to develop (see \chref{ch:background}), it is sensible to assume that \emph{all} languages operate in this way. Lexemes should be described in terms of the range of contexts they appear in, how frequently they appear in those contexts, and the semantic shifts they undergo in different context, rather than as rigidly belonging to one class of words or another.

A third finding from this dissertation is that there are also principled limits on flexibility. For starters, the degree of flexibility for any given lexical item appears to be synchronically fixed. Speakers know the range of contexts that a given form may appear in and generally operate within that range of conventionally-established uses. To put it another way, speakers know which form-function pairings are conventionalized, and the semantic shifts associated with them. They do not appear to be productively using forms for new discourse contexts all the time as the situation dictates. If this were the case, we would a) expect a higher overall degree of flexibility even for a language like \idx{Nuuchahnulth}, and b) might expect to see a great deal more stochasticity in the cumulative flexibility ratings for a form (see \secref*{sec:4.4}). It would also be difficult to explain why some forms display greater or lesser flexibility than others. Instead, it appears that forms are conventionally used for certain functions, with individual lexemes varying as to which and what range of functions they are conventionalized in.

Lexical flexibility also adheres to well-established crosslinguistic patterns. The fact that human animates are among the lowest flexibility items in both \idx{English} and \idx{Nuuchahnulth} is consistent with the hypothesis of frequential markedness, wherein lexemes are used most frequently in their most prototypical function \parencites{Croft1991}{Croft2000}{Croft2001b}{CroftLier2012}. Additionally, the near-mutually exclusive nature of definite marking and aspect marking in Nuuchahnulth shows that even extremely flexible languages nonetheless adhere to the pattern that prototypical uses of a word are more likely to exhibit inflectional marking characteristic of their class (and by extension, that non-prototypical uses are less likely to show such inflection) \parencite{HopperThompson1984}.

Overall, the findings in this dissertation confirm much of what we thought we knew about lexical flexibility and its behavior in individual languages. Researchers have noted the flexibility of \idx{Nuuchahnulth}—particularly between reference and predication—for almost a century, and the data have shown this impression to be true. Researchers generally see English lexical categories as fairly well defined, but acknowledge the many cases of functional shift as well. Again, the data show this impression to be correct. We can now say for the first time that these impressions are indeed backed by quantitative empirical evidence. The methods in this dissertation open the door to exploring all sorts of other questions about lexical flexibility in an empirically rigorous way, which I now turn to in the following section.

\section{Limitations \& future research}
\label{sec:5.4}

By far the biggest limitation of this study was the size of the two corpora utilized. For \idx{English}, the limiting factor was how large the corpus is, while for \idx{Nuuchahnulth} the limiting factor was how small the corpus is. In total I manually annotated approximately 380,000 tokens of English for the 100-item sample, a process which took about three months of regular work. Obviously, scaling this to additional words or corpora would require a huge investment of person-hours, but this is the logical next step. We could gain a much more comprehensive picture of English by looking at a 1,000-item sample, for example, perhaps carefully sampled from different semantic classes of words.

While the \idx{Nuuchahnulth} corpus is sizeable for a documentary corpus ($\sim$8,300 tokens), Zipf's law entails that the frequencies of most items in a corpus of that size will nonetheless be quite low. Fortunately, other corpora of Nuuchahnulth exist. \textcite{Nakayama2001} mentions that he recorded other texts not included in \textcite{Little2003} or \textcite{Louie2003}. \textcite{SapirSwadesh1939} also collected an extensive collection of texts in Nuuchahnulth. Typing up this corpus for digital annotation and searching would only take a few weeks (it took me approximately four weeks to type the entire Nakayama corpus), and would result in a significantly larger corpus, and a more accurate picture of flexibility in Nuuchahnulth.

The fact that the \idx{Nuuchahnulth} corpus contains interlinear glossing also makes it possible to investigate a wide range of research questions unavailable to flat corpora like the OANC. Thanks to Nakayama's detailed analysis, future research can explore the correlations between flexibility or discourse function and any kind of morphological marking. One could explore, for example, whether different kinds of aspect marking correlate more strongly with certain discourse functions over others. For many languages, it is also possible to do some automated annotation of discourse function based purely on morphological criteria. If it is known that a given morpheme in a language is only ever used in one discourse function, then researchers can programmatically annotate every token containing that morpheme, saving a good deal of manual annotation. Interlinearized glossed documentary corpora are thus highly compatible with research into lexical flexibility.

There are a few other obvious ways in which to expand the empirical coverage on lexical flexibility. First, we can examine additional languages. It is my hope that other researchers will adopt the quantitative methods presented in \chref{ch:methods} and apply them to the investigation of a range of languages. In particular, it would be good to empirically verify the claims that have been made about flexibility or non-flexibility in the following languages:

\begin{itemize}

  \singlespacing

  \item \textbf{Cayuga}\index{Cayuga} has been the center of a debate on lexical flexibility \parencites{Sasse1988}{Sasse1993}{Mithun2000}.

  \item \textbf{Classical Nahuatl}\index{Nahuatl} is famously claimed to exhibit omnipredicativity \parencites{Launey1994}{Launey2004}. It is worth investigating this empirically to see just how often stems are used to predicate in the language.

  \item \textbf{Latin}\index{Latin} is the idealized model of a language with rigid parts of speech. It would be interesting to see whether lexical categories are as inflexible in the language has is generally assumed.

  \item \textbf{Mandarin}\index{Mandarin} is a strongly isolating language with few morphological indications of discourse function, sometimes claimed to lack parts of speech \parencites{McDonald2013}{Sun2020}.

  \item \textbf{Riau Indonesian}\index{Indonesian} is claimed to have no parts of speech whatsoever \parencite{Gil1994}, but this has not yet been shown in a comprehensive way.

  \item \textbf{Swahili}\index{Swahili} and other Bantu languages seem to show a great deal of referent-predicate flexibility for stems, but have never to my knowledge been discussed in the literature on lexical flexibility.

  \item \textbf{Spanish and French}\index{Spanish}\index{French} are both generally thought to display little to no flexibility, but hardly any work has been done to show this \parentext{though see \parencite{Kihm2017}}.

  \item \textbf{Pacific Northwest} languages all show similar tendencies to \idx{Nuuchahnulth} according to the existing literature. It would be interesting to see whether they do in fact pattern in similar ways.

\end{itemize}

\noindent Of course, if we are interested in generating crosslinguistic generalizations and/or implicational universals regarding lexical flexibility, a balanced sample of languages worldwide would be more appropriate.

Examining a range of languages like this also allows for the investigation of any correlations between flexibility and morphological type, potentially answering such questions as, \enquote{Are isolating languages more flexible than synthetic ones?}. \parentext{\textcite{Vonen1994} argues, for example, that typological similarities between \idx{English} and Tokelau account for the fact that both languages are fairly flexible.}

Another way that, in retrospect, I wish I had extended the empirical coverage for this study is to include adverbial (predicate modifying) uses of stems as well. I suspect that the overall flexibility rating of \idx{English} may have been significantly lower had predicate modifiers been included in the analysis. I recommend that any future researchers include this category in their analysis as well. This does not affect the calculation of the flexibility rating for each stem in any meaningful way: the number of levels will simply be $4$ instead of $3$. Shannon's $H$ should still be an accurate representation of the functional diversity of each stem when applied in this way.

Other research desiderata would require additional coding beyond what was done here. For example, a more thorough investigation of the semantics of lexical flexibility would require tagging each stem for its semantic class(es) and/or features. One could also investigate the effect of blocking (the existence of an overtly-derived form which preempts the use of a stem in that discourse function) by annotating each stem for whether an overtly-derived counterpart exists. I suspect that the flexibility ratings for blocked forms will be very low but not necessarily zero (as evidenced by the fact that one can use \txn{know} as a referent in \idx{English} despite the existence of the potential blocker \txn{knowledge}).

I also believe that one of the most important areas in need of investigation is the diachrony of lexical flexibility. Since competing diachronic forces can change the overall flexibility of a language in either direction, it is important to understand exactly how these changes take place. Studies that examine the trajectory of individual lexemes and how their flexibility evolved over time would be especially valuable. The long history of written documentation for \idx{English} and other European languages also makes it possible to determine whether languages change significantly in their overall flexibility over time. One could study this by comparing the flexibility of corpora of \idx{Old English} with Modern English, or \idx{Old French} with Modern French. Some work has already been done in this area \parencites[414]{Cannon1985}{Kastovsky1996}, suggesting that English has become more flexible over time, starting with the paradigm leveling that took place in \idx{Middle English}. Within English, one could also compare the flexibility of words of Germanic origin with words of Romance origin, to see if there are notable flexibility effects based on source language.

The number of research questions this project spawned is vastly greater than the ones addressed in this dissertation itself. However, I hope to have shown that it is possible to answer these questions in an empirically adequate way, using the methodological foundations set forth here.

\section{Conclusion}
\label{sec:5.5}

This dissertation makes three primary contributions, one methodological, one theoretical, and one empirical. The methodological contribution is the creation of a metric for measuring the lexical flexibility of individual lexemes in a language, using the Shannon diversity index. This metric nicely captures the intuition behind lexical flexibility in a way that can be consistently applied across lexemes and languages. Theoretically, I have argued for a reversal of the canonical position on parts of speech. Rather than viewing lexical flexibility as something exotic, and as a problem for theories of lexical categories, I argue that lexical flexibility is a fundamental design feature of language. Lexical flexibility exists in all cases where a language has yet to develop dedicated morphological strategies for different discourse functions, or where diachronic changes in the language have leveled such distinctions over time, or where multiple zero-coded constructions have developed for the same function. Finally, the empirical contribution of this thesis is a first comprehensive understanding of just how lexical flexibility operates in \idx{English} and \idx{Nuuchahnulth}.
