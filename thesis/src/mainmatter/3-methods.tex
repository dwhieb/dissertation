\chapter{Data \& Methods}
\label{ch:methods}

\blockquote{This chapter describes the data used for this study, and how those data were analyzed. It covers the selection criteria for languages and lexemes, which corpora were used, and how the data were obtained and formatted. I also describe the methods used to annotate the data, and factors that influenced how the data were coded. I present and explain a measure of corpus dispersion that is used partly in place of, and partly as a complement to, raw frequencies of lexemes. Lastly, I set forth a procedure for operationalizing and quantifying lexical flexibility in a crosslinguistically comparable way. The formulation of this lexical flexibility measure is a key methodological contribution of this thesis.}

\section{Introduction}
\label{sec:3.1}

The process of collecting, annotating, and analyzing the data for this study adheres to several self-imposed principles. First and foremost, the data in this study are naturalistic discourse data rather than elicited data. This principle has two motivations: First, as discussed in \secref*{sec:1.2}, few studies examine token frequencies of lexical items used for different discourse functions, and those that do only report aggregated results. Most extant research consists of lexicon-based counts. This study therefore explores a previously unexamined aspect of lexical flexibility. Second, corpus-based methods study real-world instances of language in use, rather than made-up examples or examples produced by introspection, which are subject to various cognitive and social biases \parencite[168]{Baker2018}. \addcite{Kahnemann \& Tversky (1973), Mynatt et al. (1977), Vallone et al. (1985), Haselton et al. (2005), all cited in Baker (2018: 168)} Corpus data are also more likely to reveal prototype effects through statistical tendencies. For this study, I relied on specialized corpora of spoken narrative and conversational texts only. This ensures greater comparability between the corpora used in this study and other documentary corpora that these methods may be applied to in the future, since most documentary corpora likewise consist of spoken narratives and conversations.

The second self-imposed requirement for this study is adherence to the \href{https://site.uit.no/linguisticsdatacitation/}{Austin principles of data citation in linguistics} \parencite{BerezKroekeretal2018}. In particular, the source for each data point discussed in this thesis is uniquely identified with its location in the corpus, and the data used in this study are made freely available on GitHub at \url{https://github.com/dwhieb/dissertation}. All of the data and my annotations on that data may be viewed there.

Finally, as a matter of scientific accountability, this study is designed to be replicable using the same or other datasets. All of the technical details regarding how to acquire the data, annotate it, and run statistical analyses for those data are documented in the GitHub repository for this project, which may be viewed at \url{https://github.com/dwhieb/dissertation}.

\section{Data}
\label{sec:3.2}

\section{Methods}
\label{sec:3.3}

\section{Analysis}
\label{sec:3.4}
