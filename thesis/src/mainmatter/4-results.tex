\chapter{Results}
\label{ch:results}

\blockquote{This chapter reports the results of applying the procedures described in \hyperref[ch:methods]{Chapter 3: Data \& Methods}. I begin by demonstrating for the reader how to interpret the ternary plots used to visually represent the degree of lexical flexibility for individual items (\ref{R1}) (\secref*{sec:4.2}). Next I look at the flexibility of lexical items in English and Nuuchahnulth, both independently and in comparison (\secref*{sec:4.3}). I then I investigate whether lexical flexibility depends on corpus size (\ref{R2}) (\secref*{sec:4.4}). Next, examine the relationship between the degree of lexical flexibility and frequency / dispersion (\ref{R3}) (\secref*{sec:4.5}). Finally, I discuss the behavior of flexible items with respect to their semantics (\ref{R4}) (\secref*{sec:4.6}).}

\section{Introduction}
\label{sec:4.1}

This chapter presents the empirical findings from this study, answering the research questions posed in \chref{ch:introduction}. I employ a useful visualization for displaying information about lexical flexibility called a \dfn{ternary plot} or \dfn{triangle plot}; I explain how these ternary plots are to be read in \secref*{sec:4.2}. \secref*{sec:4.3} focuses on answering \ref{R1}, \enquote{How flexible are lexical items in English and Nuuchahnulth?}, both individually and in comparison. \secref*{sec:4.3} is dedicated to answering \ref{R2}, \enquote{Is there a correlation between degree of lexical flexibility and size of the corpus?}, and \secref*{sec:4.4} answers \ref{R3}, \enquote{Is there a correlation between degree of lexical flexibility for a lexical item and frequency (or corpus dispersion)?}. In the final section (\secref{sec:4.6}), I look at the semantic behavior of more and less flexible items (question \ref{R4}).

\section{Interpreting the results}
\label{sec:4.2}

In \secref*{sec:3.4.1} I describe the procedure for quantifying the lexical flexibility of an item in a corpus using a Shannon diversity index ($H$). While the resulting values nicely align with our intuitions about when a lexical item is more or less flexible, some information is lost in the process. Reducing the lexical flexibility of an item to a single number obscures the fact that items can be equally flexible in different ways. Consider the fictional frequency data for two different stems in \tabref{tab:equal-flexibility-stems}. Stem A displays a great deal of reference-predicate flexibility, but very few instances of use as a modifier. Stem B, in contrast, displays extensive reference-modifier flexibility, but few instances of use as a predicate. However, the overall flexibility ratings of the two stems are the same.

\TODO[inline]{add table}

One way to address this reduction in fidelity is to report frequencies and corpus dispersions for each function in addition to the overall flexibility rating for each stem. I provide this information in \appref{app:100-item-samples} alongside each item's flexibility rating. However, it is also possible to visualize the relative usage of an item for each discourse function in an intuitive way by using a \dfn{ternary plot} (also called a \dfn{triangle plot}, \dfn{simplex plot}, \dfn{Gibbs triangle}, or \dfn{de Finetti diagram}). A ternary plot depicts the ratios of three variables as points within an equilateral triangle. Each corner of the triangle corresponds to one of the three possible categories (in this case, reference, predication, or modification). The closer a data point is to a particular corner, the larger the ratio of that category is. To illustrate with an example: \figref{fig:difficult} is a ternary plot for the functions of the word \txn{difficult} in English, along with the underlying frequency data and resulting flexibility rating.

\TODO[inline]{add ternary plot for `difficult', along with underlying data}

\noindent Because the word \txn{difficult} only appears as a modifier in the corpus, it has a flexibility rating of $0$. In the ternary plot, this is evident from the fact that the plot point for \txn{difficult} sits in the modification corner of the triangle.

Compare the plot for \txn{difficult} in \figref{fig:Eng-difficult} to that of \txn{away} in \figref{fig:Eng-away}.

\TODO[inline]{add ternary plot for `away', along with underlying data}

\noindent The stem \txn{anything} also has a flexibility rating of $0$ because all of its tokens are used for reference. Even though its flexibility rating is the same as that of \txn{difficult}, it is plotted in a different corner of the ternary plot (reference).

\figref{fig:Eng-childhood} shows a case where a stem (\txn{childhood}) is flexible between reference and modification, but not predication.

\TODO[inline]{add ternary plot for `childhood', along with underlying data}

\noindent A perfectly flexible item which has equal use as a referent, predicate, and modifier, would sit exactly in the center of the triangle. The Nuuchahnulth stem \txn{ʔu·q} \tln{good} is one such case, shown in \figref{fig:Nuu-good}. The closer a point is towards the center of the triangle, the more flexible it is.

\TODO[inline]{add ternary plot for Nuuchahnulth 'good', along with underlying data}

Finally, remember from \chref{ch:methods} that corpus dispersion is a better measure of frequency of exposure than just raw frequency. Thus in addition to relative frequency data, I also report corpus dispersions for the discourse functions of each lexical item in \appref{app:100-item-samples}. Note that the corpus dispersions are calculated separately for each discourse function (in addition to the overall corpus dispersion of the lexical item). A particular lexical item might be used for one function evenly throughout the corpus, and thus have a low $DP$ for that function, but might only be used for another function in one or two texts, thus giving that function a high $DP$. The ratios of these corpus dispersions for each function can be plotted on a ternary plot just like frequency. Plots based on corpus dispersions are sometimes notably different from plots based on frequencies, as \figref{sec:plot-frequency-vs-dispersion} illustrates. In most cases however the plots are identical or near-identical. As such, for the remainder of this study I will use ternary plots based on corpus dispersion rather than frequency, noting where the two diverge only when relevant.

\TODO[inline]{compare ternary plots for frequency and dispersion where they differ significantly}

\section{R1: Degree of lexical flexibility}
\label{sec:4.3}

In this section I examine the degree of lexical flexibility for words in English and Nuuchahnulth from several angles, both independently and in comparison, using the lexical flexibility ratings calculated with the methods in \secref*{sec:3.4.1}. The result of these calculations for the 100-item samples are shown in \appref{app:100-item-samples}, and a selection of the results appear in \tabref{tab:English-sample} for English and \tabref{tab:Nuuchahnulth-sample} for Nuuchahnulth.

\TODO[inline]{add English-sample table, based on the one in your colloquium talk}

\TODO[inline]{add Nuuchahnulth-sample table, based on the one in your colloquium talk}

\figref{fig:histogram-100-items} visualizes these flexibility ratings for the 100-item samples from English (lefthand side) and Nuuchahnulth (righthand side). The top portion of each figure is a histogram showing the number of lexical items at different flexibility ratings, providing an approximate representation of the distribution of the flexibility ratings. Beneath the histograms are boxplots showing the median flexibility rating for each language.

\TODO[inline]{add the histograms (with boxplots) for the 100-item samples}

\noindent \figref{fig:histogram-small-corpus} shows the same visualizations for the small corpus samples.

\TODO[inline]{add the histograms (with boxplots) for the small corpus samples}

\noindent Tables \ref{tab:100-item-stats} and \ref{tab:small-corpus stats} summarize basic descriptive statistics for each of the samples.

\TODO[inline]{tables showing min, max, mean, median for each sample}

One immediately obvious observation to be made from these flexibility ratings is that individual lexical items may vary widely in their flexibility, both within and across languages. While this finding is entirely unsurprising, the results very well could have been otherwise. The way Nuuchahnulth is often described, one might expect all the lexical items in the language to fall within a more limited range of high-flexibility values. This is clearly not the case. Flexibility ratings for Nuuchahnulth range from the theoretical minimum of $0$ to a maximum of $.920$ or $0.000$ depending on the sample.\TODO{update these values} However, \TODO{XX (XX\%)} of the small corpus Nuuchahnulth sample have a flexibility rating of $0$ (\TODO{XX or XX\% for the 100-item sample}), potentially challenging the claim that all Nuuchahnulth stems are flexible.

Likewise, those who claim that English parts of speech are well defined must confront the fact that the range of flexibility values for English is nearly the same as for Nuuchahnulth for both samples: $0$ on the lower end and $.919$ or $0.000$ on the upper end.\TODO{update these values} In fact, in both samples there are fewer English stems with a flexibility rating of $0$ than there are Nuuchahnulth stems with a flexibility rating of $0$.\TODO{verify that this is true} In this respect, then, English could be viewed as more flexible than Nuuchahnulth. Of course, it may be that this difference is due to the large difference in corpus sizes between English and Nuuchahnulth, an issue which is explored in \secref*{sec:4.4}.

Thus the answer to the question, \enquote{Are some lexical items more flexible than others?} is unsurprisingly \enquote{yes}. To pose a related question, \enquote{Can it be shown empirically and quantitatively that some lexical items are more flexible than others, as many linguists have claimed?}. The answer is again, \enquote{yes}. If we want to evaluate the claim that some languages are more or less flexible than others, it must be possible to quantify that flexibility at the level of the individual lexical item and compare them in a meaningful way. The data and methods in this thesis show that this is indeed possible, and that we can provide clear empirical answers to these kinds of questions. The flexibility of individual lexical items varies widely both within and between languages.

A slightly different question than whether individual stems vary in their flexibility is whether they exhibit flexibility to any substantive degree in the first place. Or, to invert the question, is lexical flexibility a marginal / rare phenomenon which has merely been given disproportionate attention in the literature? A quick look at the flexibility data above shows that this is not the case. When lexical items in English and Nuuchahnulth exhibit flexibility, it is typically not to a marginal degree. A stem is more likely to have a flexibility of, say, $.2$ than something like $.002$. According to a one-sided, one-sample sign test, the median flexibility in all samples differs highly significantly from zero (see the summary table in \tabref{tab:English-vs-Nuuchahnulth-median}).

% (English: $V = 4371$, $p < .0001$; Nuuchahnulth: $V = 20503$, $p < .0001$).
\TODO[inline]{summarize the statistical results comparing the median flexibility in a table}

This result may seem obvious, but it must be recognized that the result could have been different. Flexibility for English stems could have been so marginal as to not significantly deviate from zero. This would have supported an analysis of lexical flexibility in English as mere occasional language play, something exceptional rather than rampant or productive. The data show otherwise: lexical flexibility is a prevalent feature of both English and Nuuchahnulth, though to different degrees.

Another obvious question to ask of these data is whether English and Nuuchahnulth differ in their overall flexibility. The answer to this is clearly \enquote{yes}, as the mean and median flexibility ratings in Tables \ref{tab:100-item-stats} and \ref{tab:small-corpus-stats} show. The mean flexibility ratings are higher for Nuuchahnulth than English in both samples. \TODO{verify this} But to reduce the entire lexicon of a language to a single average obscures important details. While it is certainly interesting that Nuuchahnulth stems are on net more flexible than English stems, the way in which the two languages exhibit flexibility is arguably the more interesting finding from this study.

How then is lexical flexibility realized in English and Nuuchahnulth? In addition to the histograms in Figures \ref{fig:histogram-100-items} and \ref{fig:histogram-small-corpus}, the ternary plots in Figures \ref{fig:ternary-100-items} and \ref{fig:ternary-small-corpus} illustrate just how flexibility operates in the two languages. In these figures, each lexical item is represented by a single point on the ternary plot.

\TODO[inline]{add ternary plots comparing English vs. Nuuchahnulth for both samples}

Beginning with English, we can see that most lexical items exhibit some flexibility, but to a relatively small degree. After zero-flexibility cases, the next most frequent flexibility rating is in the $0$–$0.05$ range. This is evident from the ternary plots, where lexical items tend to cluster near (but not precisely on) the corners for their most prototypical functions. Interestingly, the small English corpus appears to show \emph{more} flexibility than the 100-item sample. This could be an effect of the specific words chosen, but it could also be the case that it takes a certain number of tokens for the prototypical function of an item to become evident. This possibility is examined further in \secref*{sec:4.4}.

Nuuchahnulth differs from English in several notable ways. First, a much higher proportion of items display no flexibility whatsoever. However, for those items which do exhibit flexibility, the average flexibility rating is generally higher than that of English stems. In both samples, the biggest cluster of items with non-zero flexibility ratings have ratings around $.6$. English items with non-zero flexibility, by comparison, generally have ratings closer to $.2$. Thus for Nuuchahnulth lexical items are either totally inflexible or generally strongly flexible.

This bifurcation of the data is very likely due to the small size of the Nuuchahnulth corpus, as the discussion in \secref*{sec:4.4} suggests. It may be that Nuuchahnulth words are generally highly flexible, but that more tokens are needed to see this trend. Alternatively, it may be that certain Nuuchahnulth stems are strongly associated with a specific discourse function and thus inflexible, while others are generally flexible. This would suggest a probabilistic division of Nuuchahnulth stems into two classes: those that are productively flexible, and those that are not.

This second possibility would challenge existing analyses of Nuuchahnulth. The existence of a productively flexible class of stems would be counterevidence to the many claims that Nuuchahnulth word classes can in fact be clearly defined using selectional criteria such as ability to take possession or the definite suffix \addcite{citations}. Similarly, \textcite[???]{Nakayama2001} characterizes word classes in Nuuchahnulth as \enquote{strong statistical tendencies} \TODO{get exact phrasing and page for this}. For many Nuuchahnulth stems, however, there is no clear prototypical use. Many stems are used roughly as equally for predication as they are for reference, making it difficult to assess which use is more basic or unmarked.

As the ternary plots for Nuuchahnulth in \figref{fig:ternary-100-items} and \figref{fig:ternary-small-corpus} make clear, the distribution of lexical items across functions in Nuuchahnulth differs strongly from that of English. For starters, there is very little clustering around prototypical functions in the corners, in direct contrast to English. Secondly, Nuuchahnulth shows very little flexibility in the modification direction, but rampant flexibility along the reference-predication axis. For the small corpus sample in particular, there is a smooth cline of values between reference and predication. Nuuchahnulth stems sit anywhere on a continuum from prototypical referents to prototypical predicates, but none show prototypical modifier behavior.

These findings nicely reflect the intuitions of many researchers about these two languages. English is mostly rigid, but most words exhibit a marginal degree of flexibility. English words are \emph{primarily} associated with one discourse function, but not exclusively so. Nuuchahnulth, by contrast, shows a very high degree of reference-predicate flexibility. However, Nuuchahnulth stems are not frequently used for modification. This is in line with the analysis of most researchers regarding lexical categories in Nuuchahnulth. \textcite[50]{Nakayama2001}, for example, says that the categories noun and verb must be recognized for Nuuchahnulth, but that there is not sufficient evidence to justify an adjective category, even as a statistical tendency. He instead treats \enquote{adjectivals} as a subclass of verbs; the central location of the points in the Nuuchahnulth plot in \figref{fig:ternary-small-corpus}, however, suggest that Nuuchahnulth modifiers are as nounlike as they are verblike. The low frequency with which stems are used for modification also mirrors the results from \posscitet[88--89]{Croft1991} four-language survey of the textual frequency of different lexical classes. He also finds that \textquote[{\cite[88--89]{Croft1991}}]{the overall frequency of roots denoting properties and occurrences of modifiers is extremely low compared to the frequencies of object and action roots and of referring expressions and predications}.

\section{R2: Lexical flexibility and corpus size}
\label{sec:4.4}

It seems intuitively plausible that the more tokens of a word one encounters, the more likely one is to find flexible uses of a word. With a large enough corpus, all items would exhibit flexibility. This has been claimed by \textcite[77]{MoselHovdhaugen1992}. It may be the case that larger corpora are statistically more flexible than smaller corpora. However, to my knowledge this claim has never been tested empirically. In this section I examine the results of comparing the number of tokens encountered for a stem to its cumulative flexibility rating, the question being, \enquote{Does the cumulative flexibility for the lexical item increase as one encounters more tokens?}.

It is important to understand here that number of tokens encountered is not the same thing as frequency. A very low-frequency word could nonetheless have a high number of tokens in a given corpus if that corpus is very large. Likewise, a high-frequency word could have a low number of tokens in a small corpus.

Only stems with a frequency of at least 4 were included (see \secref{sec:3.4.1} for the motivation behind this restriction). For English, I used the 100-item sample, and for Nuuchahnulth I used the entire corpus. Using a script and going sequentially through the corpora, each time I encountered a new token of a lexical item, I recalculated its flexibility and recorded that value and token frequency at that point in the corpus.

\figref{fig:cumulative-flexibility-words-English} shows the result of these calculations for the the ten most frequent words in the English corpus, and \figref{fig:cumulative-flexibility-words-Nuuchahnulth} shows the same for Nuuchahnulth. The number of tokens encountered is shown on the x-axis, and the cumulative flexibility is shown on the y-axis. I show only the most frequent words here merely because they provide the clearest visual representation of the data; more comprehensive (but more difficult to read) plots for each language are given in \figref{fig:cumulative-flexibility-all-English} and \figref{fig:cumulative-flexibility-all-Nuuchahnulth}. For ease of visualization, a version of the English data with $\log_{10}$ frequency on the x-axis is also given in \figref{fig:cumulative-flexibility-English-log}.

\TODO[inline]{all five plots of cumulative flexibility}

The first thing to notice from both plots of high-frequency words is that it takes a certain number of tokens for the flexibility of a word to become evident and stable. For English, the trend lines are generally no longer stochastic after $\sim$1,000 tokens encountered (this can be more easily seen in \figref{fig:cumulative-flexibility-English-log}). It we take 1,000 tokens as a reliability threshhold for determining the flexibility of a lexical item, then no Nuuchahnulth item appears with sufficient frequency in the corpus to be certain of its flexibility. That said, the flexibility of the ten words in the Nuuchahnulth sample appears to be relatively stable after 50–75 tokens. There are some words in the English sample which achieve a relatively stable flexibility rating as early as 100 tokens as well. One way to interpret these data is that, since some stems appear in a wider range of discourse contexts than others, one requires a higher number of tokens before their overall flexibility becomes evident; in contrast, the flexibility of stems that appear in a relatively small range of discourse contexts should become clear right away.

The second observation to make regarding these data on cumulative frequency is that, once the trend line for cumulative flexibility becomes smooth, it stays flat. This is in direct contradiction to the hypothesis that words will seem more flexible as one encounters more of their tokens. If this were true, we would expect to see a continual and gradual increase in flexibility for many of the stems in the dataset, and this is not the case.

On the other hand, by the time one encounters 5,000 tokens of a word in English, there are no stems with a flexibility of zero. English flexibility ratings cluster in the lower range ($\sim0.3$), but when sufficient tokens are encountered, there do not seem to be any truly inflexible words. Therefore it does seem to be true (for English at least) that words will eventually display \emph{some} flexibility as the size of the corpus increases, but not that the overall flexibility of the word will increase.

We can also look at the data for each language in aggregate. \figref{fig:cumulative-mean-flexibility-English} shows the cumulative mean flexibility for English per token encountered. Each time a new token of a lexical item was encountered, I calculated the current flexibility ratings of each lexical item encountered up to that point, and calculated their average. The resulting plot shows number of tokens encountered on the x-axis and mean flexibility for the entire corpus up to that point on the y-axis. \figref{fig:cumulative-mean-flexibility-Nuuchahnulth} shows parallel data for Nuuchahnulth. Both graphs clearly show that the average flexibility of the corpus does not increase as the corpus grows larger. Instead it remains flat after a sufficent number of tokens are encountered.

\TODO[inline]{insert plots for English and Nuuchahnulth}

To summarize, once enough tokens of a word are encountered as to give a reliable flexibility rating, that flexibility rating does not increase as the number of tokens encountered continues to grow. Lexical items appear to have (synchronically) fixed degrees of flexibility, that vary from word to word. Logically, aggregating this data at the language level produces the same result: languages have (synchronically) fixed degrees of flexibility, that vary from language to language.

\section{R3: Lexical flexibility and frequency / dispersion}
\label{sec:4.5}

In this section I examine the interactions between lexical flexibility, token frequency, and corpus dispersion for individual lexical items. Given that many linguistic phenomena correlate with frequency / corpus dispersion, it is reasonable to investigate whether lexical flexibility displays such correlations as well. Are high frequency or more evenly dispersed words more flexible than low frequency or unevenly dispersed words? This is an interesting question in part because if such a correlation were found the direction of causation could go in either direction. It may be that stems are more frequent precisely because they are more flexible—there is a wider range of discourse contexts that they can occur in. On the other hand, it could be that high frequency words are more cognitively accessible and therefore more prone to novel uses in discourse. Or, in contrast, a higher frequency could also result in a greater degree of entrenchment, so that high frequency words are less likely to be flexible.

To investigate the possible interactions among flexibility, frequency, and dispersion I deployed a Generalized Additive Model (GAM) in order to account for the possibility of interactions not just between flexibility and frequency / dispersion, but for interactions between frequency and dispersion as well. For example, it may be the case that there are correlations between flexibility and dispersion, but only for high frequency words. A Generalized Additive Model allows for the exploration of multiple interactions in this way.

\section{R4: The semantics of lexical flexibility}
\label{sec:4.6}
