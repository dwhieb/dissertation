sd(Eng_100$flexibility)
mean(Nuu_100$flexibility)
sd(Nuu_100$flexibility)
mean(Eng_small$flexibility)
sd(Eng_small$flexibility)
mean(Nuu_small$flexibility)
sd(Nuu_small$flexibility)
# Assumption of the t-test: The data are normally distributed.
# Test for normality (H0 = normal distribution; H1 = non-normal distribution)
shapiro.test(Eng_100$flexibility)   # W = 0.87914, p < .0001
shapiro.test(Nuu_100$flexibility)   # W = 0.93616, p < .0001
shapiro.test(Eng_small$flexibility) # W = 0.93616, p < .0001
shapiro.test(Nuu_small$flexibility) # W = 0.93616, p < .0001
wilcox.test(
Eng_100$flexibility,
alternative = "greater",
mu = 0
) # V = 4371, p < .0001
wilcox.test(
Nuu_100$flexibility,
alternative = "greater",
mu = 0
) # V = 4371, p < .0001
wilcox.test(
Eng_small$flexibility,
alternative = "greater",
mu = 0
) # V = 4371, p < .0001
wilcox.test(
Nuu_small$flexibility,
alternative = "greater",
mu = 0
) # V = 4371, p < .0001
mean(Eng_100$flexibility)
mean(Nuu_100$flexibility)
mean(Eng_small$flexibility)
mean(Nuu_small$flexibility)
mean(Eng_100$flexibility)
median(Eng_100$flexibility)
sd(Eng_100$flexibility)
sd(Nuu_100$flexibility)
?sd
mean(Nuu_100$flexibility)
median(Nuu_100$flexibility)
sd(Nuu_100$flexibility)
mean(Eng_small$flexibility)
median(Eng_small$flexibility)
sd(Eng_small$flexibility)
mean(Nuu_small$flexibility)
median(Nuu_small$flexibility)
sd(Nuu_small$flexibility)
library(ggplot2)
load_data <- function(file_path) {
data <- read.table(
file_path,
colClasses = c(
"character",
"integer",
"integer",
"integer",
"integer",
"numeric"
),
col.names = c(
"stem",
"REF",
"PRED",
"MOD",
"tokens_observed",
"flexibility"
),
comment.char = "",
encoding     = "UTF-8",
header       = FALSE,
quote        = "",
sep          = "\t",
)
return(data)
}
data_Nuu <- load_data("stats/data/Nuuchahnulth_corpus_size.tsv")
data_Eng <- load_data("stats/data/English_corpus_size.tsv")
plot_Nuu <- ggplot(data_Nuu, aes(
x     = tokens_observed,
y     = flexibility,
color = stem
)) +
ylab("flexibility (Shannon's H)") +
xlab("# tokens observed") +
theme_minimal() +
theme(plot.title = element_blank()) +
ylim(0, 1) +
geom_point(
show.legend = FALSE,
size        = 0.5
)
ggsave(
"stats/figures/corpus_size/Nuuchahnulth.png",
plot_Nuu,
height = 5,
width  = 10
)
plot_Eng <- ggplot(data_Eng, aes(
x = tokens_observed,
y = flexibility
)) +
ylab("flexibility (Shannon's H)") +
xlab("# tokens observed") +
theme_minimal() +
theme(plot.title = element_blank()) +
ylim(0, 1) +
geom_point(
show.legend = FALSE,
size        = 0.5
) # +
# scale_x_continuous(trans="log10")
ggsave(
"stats/figures/corpus_size/English.png",
plot_Eng,
height = 10,
width  = 20
)
high_frequency_Eng_words <- c(
"know",
"think",
"one",
"thing",
"right",
"say",
"see",
"time",
"good",
"year"
)
data_Eng_words <- data_Eng[data_Eng$stem %in% high_frequency_Eng_words, ]
plot_Eng_words <- ggplot(data_Eng_words, aes(
x = tokens_observed,
y = flexibility,
color = stem
)) +
ylab("flexibility (Shannon's H)") +
xlab("# tokens observed") +
theme_minimal() +
theme(plot.title = element_blank()) +
ylim(0, 1) +
geom_point(
show.legend = TRUE,
size        = 1
) # +
# scale_x_continuous(trans="log10")
ggsave(
"stats/figures/corpus_size/English_high_freq.png",
plot_Eng_words,
height = 5,
width  = 10
)
high_frequency_Nuu_words <- c(
"wa·",
"wik",
"waː",
"qʷaː",
"ʔaḥʔaː",
"ʔaḥ",
"čuː",
"quːʔas",
"qʷayac̓iːk",
"qʷis"
)
data_Nuu_words <- data_Nuu[data_Nuu$stem %in% high_frequency_Nuu_words, ]
plot_Nuu_words <- ggplot(data_Nuu_words, aes(
x = tokens_observed,
y = flexibility,
color = stem
)) +
ylab("flexibility (Shannon's H)") +
xlab("# tokens observed") +
theme_minimal() +
theme(plot.title = element_blank()) +
ylim(0, 1) +
geom_point(
show.legend = TRUE,
size        = 1
)
ggsave(
"stats/figures/corpus_size/Nuuchahnulth_high_freq.png",
plot_Nuu_words,
height = 5,
width  = 10
)
plot_Eng_words <- ggplot(data_Eng_words, aes(
x = tokens_observed,
y = flexibility,
color = stem
)) +
ylab("flexibility (Shannon's H)") +
xlab("# tokens observed") +
theme_minimal() +
theme(plot.title = element_blank()) +
ylim(0, 1) +
geom_point(
show.legend = TRUE,
size        = 1
) # +
# scale_x_continuous(trans="log10")
ggsave(
"stats/figures/corpus_size/English_high_freq.png",
plot_Eng_words,
height = 5,
width  = 10
)
plot_Eng <- ggplot(data_Eng, aes(
x = tokens_observed,
y = flexibility
)) +
ylab("flexibility (Shannon's H)") +
xlab("# tokens observed") +
theme_minimal() +
theme(plot.title = element_blank()) +
ylim(0, 1) +
geom_point(
show.legend = FALSE,
size        = 0.5
) # +
# scale_x_continuous(trans="log10")
ggsave(
"stats/figures/corpus_size/English.png",
plot_Eng,
height = 5,
width  = 10
)
plot_Eng <- ggplot(data_Eng, aes(
x = tokens_observed,
y = flexibility
)) +
ylab("flexibility (Shannon's H)") +
xlab("# tokens observed") +
theme_minimal() +
theme(plot.title = element_blank()) +
ylim(0, 1) +
geom_point(
show.legend = FALSE,
size        = 0.5
) +
scale_x_continuous(trans="log10")
ggsave(
"stats/figures/corpus_size/English_log10.png",
plot_Eng,
height = 5,
width  = 10
)
library(ggplot2)
load_data <- function(file_path) {
data <- read.table(
file_path,
colClasses = c(
"character",
"integer",
"integer",
"integer",
"integer",
"numeric"
),
col.names = c(
"stem",
"REF",
"PRED",
"MOD",
"tokens_observed",
"flexibility"
),
comment.char = "",
encoding     = "UTF-8",
header       = FALSE,
quote        = "",
sep          = "\t",
)
return(data)
}
data_Nuu <- load_data("stats/data/Nuuchahnulth_corpus_size.tsv")
data_Eng <- load_data("stats/data/English_corpus_size.tsv")
high_frequency_Nuu_words <- c(
"wa·",
"wik",
"waː",
"qʷaː",
"ʔaḥʔaː",
"ʔaḥ",
"čuː",
"quːʔas",
"qʷayac̓iːk",
"qʷis"
)
data_Nuu_words <- data_Nuu[data_Nuu$stem %in% high_frequency_Nuu_words, ]
data_Nuu_words
?cat
?paste
data_Nuu_words <- data_Nuu[data_Nuu$stem %in% high_frequency_Nuu_words, ]
plot_Nuu_words <- ggplot(data_Nuu_words, aes(
x = tokens_observed,
y = flexibility,
color = stem
)) +
ylab("flexibility (Shannon's H)") +
xlab("# tokens observed") +
theme_minimal() +
theme(plot.title = element_blank()) +
ylim(0, 1) +
geom_point(
show.legend = TRUE,
size        = 1
) +
scale_color_manual(labels = c(
"wa· ‘say’",
"wik ‘not’",
"waː ‘word’",
"qʷaː ‘thus’",
"ʔaḥʔaː ‘that’",
"ʔaḥ ‘this’",
"čuː ‘move’",
"quːʔas ‘person, man’",
"qʷayac̓iːk ‘wolf’",
"qʷis ‘do.so’"
))
ggsave(
"stats/figures/corpus_size/Nuuchahnulth_high_freq.png",
plot_Nuu_words,
height = 5,
width  = 10
)
data_Nuu_words <- data_Nuu[data_Nuu$stem %in% high_frequency_Nuu_words, ]
data_Nuu_words$stem <- c(
"wa· ‘say’",
"wik ‘not’",
"waː ‘word’",
"qʷaː ‘thus’",
"ʔaḥʔaː ‘that’",
"ʔaḥ ‘this’",
"čuː ‘move’",
"quːʔas ‘person, man’",
"qʷayac̓iːk ‘wolf’",
"qʷis ‘do.so’"
)
plot_Nuu_words <- ggplot(data_Nuu_words, aes(
x = tokens_observed,
y = flexibility,
color = stem
)) +
ylab("flexibility (Shannon's H)") +
xlab("# tokens observed") +
theme_minimal() +
theme(plot.title = element_blank()) +
ylim(0, 1) +
geom_point(
show.legend = TRUE,
size        = 1
)
ggsave(
"stats/figures/corpus_size/Nuuchahnulth_high_freq.png",
plot_Nuu_words,
height = 5,
width  = 10
)
data_Nuu <- load_data("stats/data/Nuuchahnulth_corpus_size.tsv")
data_Nuu_words <- data_Nuu[data_Nuu$stem %in% high_frequency_Nuu_words, ]
View(data_Nuu)
View(data_Nuu_words)
View(data_Nuu_words)
# DEPENDENCIES
library(mgcv)
# UTILITIES
load_data <- function(file_path) {
data <- read.table(
file_path,
na.strings = "NULL",
colClasses = c(
"character", # lexeme
"character", # gloss
"integer",   # token frequency
"numeric",   # relative frequency
"numeric",   # flexibility
"numeric",   # dispersion
),
comment.char = "",
encoding     = "UTF-8",
header       = TRUE
)
return(data)
}
# DATA
# English small corpus sample
data_Eng_small <- load_data("Eng_small.csv")
# Nuuchahnulth small corpus sample
data_Nuu_small <- load_data("Nuu_small.csv")
# English 100-item sample
data_Eng_100              <- load_data("Eng_100.csv")
data_Eng_100$log_rel_freq <- log2(data_Eng_100$rel_freq)
# Nuuchahnulth 100-item sample
data_Nuu_100              <- load_data("Nuu_100.csv")
data_Nuu_100$log_rel_freq <- log2(data_Nuu_100$rel_freq)
# DATA
# English small corpus sample
data_Eng_small <- load_data("Eng_small.csv")
# Nuuchahnulth small corpus sample
data_Nuu_small <- load_data("Nuu_small.csv")
# English 100-item sample
data_Eng_100              <- load_data("Eng_100.csv")
data_Eng_100$log_rel_freq <- log2(data_Eng_100$rel_freq)
# Nuuchahnulth 100-item sample
data_Nuu_100              <- load_data("Nuu_100.csv")
data_Nuu_100$log_rel_freq <- log2(data_Nuu_100$rel_freq)
setwd("stats/figures/freq-DP_vs_flexibility")
# DATA
# English small corpus sample
data_Eng_small <- load_data("Eng_small.csv")
# Nuuchahnulth small corpus sample
data_Nuu_small <- load_data("Nuu_small.csv")
# English 100-item sample
data_Eng_100              <- load_data("Eng_100.csv")
data_Eng_100$log_rel_freq <- log2(data_Eng_100$rel_freq)
# Nuuchahnulth 100-item sample
data_Nuu_100              <- load_data("Nuu_100.csv")
data_Nuu_100$log_rel_freq <- log2(data_Nuu_100$rel_freq)
data_Eng_small <- load_data("Eng_small.csv")
# DEPENDENCIES
library(mgcv)
# UTILITIES
load_data <- function(file_path) {
data <- read.table(
file_path,
na.strings = "NULL",
colClasses = c(
"character", # lexeme
"character", # gloss
"integer",   # token frequency
"numeric",   # relative frequency
"numeric",   # flexibility
"numeric"    # dispersion
),
comment.char = "",
encoding     = "UTF-8",
header       = TRUE
)
return(data)
}
# DATA
# English small corpus sample
data_Eng_small <- load_data("Eng_small.csv")
?read.table
# DEPENDENCIES
library(mgcv)
# UTILITIES
load_data <- function(file_path) {
data <- read.csv(
file_path,
na.strings = "NULL",
colClasses = c(
"character", # lexeme
"character", # gloss
"integer",   # token frequency
"numeric",   # relative frequency
"numeric",   # flexibility
"numeric"    # dispersion
),
encoding     = "UTF-8"
)
return(data)
}
# DATA
# English small corpus sample
data_Eng_small <- load_data("Eng_small.csv")
# Nuuchahnulth small corpus sample
data_Nuu_small <- load_data("Nuu_small.csv")
# English 100-item sample
data_Eng_100              <- load_data("Eng_100.csv")
data_Eng_100$log_rel_freq <- log2(data_Eng_100$rel_freq)
# Nuuchahnulth 100-item sample
data_Nuu_100              <- load_data("Nuu_100.csv")
data_Nuu_100$log_rel_freq <- log2(data_Nuu_100$rel_freq)
# English small corpus sample
model_Eng_small <- gam(
flexibility ~ s(log_rel_freq) + s(dispersion) + ti(log_rel_freq, dispersion),
data   = data_Eng_small,
method = "REML",
)
summary(model_Eng_small)
# English small corpus sample
model_Eng_small <- gam(
flexibility ~ s(rel_freq) + s(dispersion) + ti(log_rel_freq, dispersion),
data   = data_Eng_small,
method = "REML",
)
summary(model_Eng_small)
# Nuuchahnulth small corpus sample
model_Nuu_small <- gam(
flexibility ~ s(rel_freq) + s(dispersion) + ti(log_rel_freq, dispersion),
data   = data_Nuu_100,
method = "REML",
)
summary(model_Nuu_small)
# English 100-item sample
model_Eng_100 <- gam(
flexibility ~ s(log_rel_freq) + s(dispersion) + ti(log_rel_freq, dispersion),
data   = data_Eng_100,
method = "REML",
)
summary(model_Eng_100)
# Nuuchahnulth 100-item sample
model_Nuu_100 <- gam(
flexibility ~ s(log_rel_freq) + s(dispersion) + ti(log_rel_freq, dispersion),
data   = data_Nuu_100,
method = "REML",
)
summary(model_Nuu_100)
